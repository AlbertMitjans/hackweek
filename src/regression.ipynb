{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac2dab-3f8f-4ad2-a254-68258cbdb874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.fft import fft, fftfreq\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as pnp\n",
    "from pennylane.templates import StronglyEntanglingLayers\n",
    "from IPython.display import clear_output\n",
    "from sklearn import preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd08f8-4974-4890-aa52-e7d70207deb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0673ef-2cec-4ece-a9a0-4c74b20f3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NUM_POINTS = 2000\n",
    "NUM_DIMENSIONS = 5\n",
    "CUSTOM_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c328c60-fd5a-4480-a697-24e59f39dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_non_uniform_fourier_series(num_frequencies: int, max_frequency: float):\n",
    "    \"\"\"Generate function f(x) that returns a sum of cosines with\n",
    "    random amplitudes, frequencies and phases.\"\"\"\n",
    "    \n",
    "    frequencies = [max_frequency * np.random.random(NUM_DIMENSIONS) for _ in range(num_frequencies)]\n",
    "    amplitudes = [random.random() for _ in range(num_frequencies)]\n",
    "    phases = [2 * np.pi * random.random() for _ in range(num_frequencies)]\n",
    "    # discontinuities = [NUM_POINTS * SAMPLE_SPACING * np.random.random(NUM_DIMENSIONS) for _ in range(num_frequencies)]\n",
    "    print(f\"Frequencies: {frequencies}\")\n",
    "    print(f\"Amplitudes: {amplitudes}\")\n",
    "    print(f\"Phases: {phases}\")\n",
    "    # print(f\"Discontinuities: {discontinuities}\")\n",
    "    def f(x: np.ndarray):\n",
    "        res = 0\n",
    "        for frequency, amplitude, phase in zip(frequencies, amplitudes, phases):\n",
    "            res += 1 * np.cos(np.dot(x, frequency) + phase)\n",
    "        return res\n",
    "    return f, frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fafa1a-3bcc-4490-831d-23f5c0abc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_regression_data(inputs: np.ndarray, noise: float = 0):\n",
    "    \"\"\"Function used to generate noisy data.\"\"\"\n",
    "    data = np.array([f(input) for input in inputs])\n",
    "    # add some random noise to data\n",
    "    noisy_data = data + np.random.normal(0, noise, data.shape)\n",
    "    return data, noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4c730-1009-43d9-be83-fb572180a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "scaler = StandardScaler()\n",
    "MAX_FREQUENCY = 5\n",
    "if CUSTOM_DATASET:\n",
    "    f, freqs = generate_non_uniform_fourier_series(num_frequencies=3, max_frequency=MAX_FREQUENCY)\n",
    "    X = np.random.random((NUM_POINTS, NUM_DIMENSIONS)) * (100 / MAX_FREQUENCY)\n",
    "    labels, Y = generate_regression_data(inputs=X, noise=0.1)\n",
    "else:\n",
    "    pp=pandas.read_csv('../data/airfoil_self_noise.dat', delimiter=\"\\t\", decimal=\".\")\n",
    "    data = pp.to_numpy()\n",
    "    X = data[:, :-1]\n",
    "    Y = data[:, -1]\n",
    "    \n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c3991-7ed7-4bc2-938b-e95ff6bf6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "if CUSTOM_DATASET:\n",
    "    all_x = np.linspace(0, 100/ MAX_FREQUENCY, 10000)\n",
    "    plt.plot(all_x, [f([x] + [0] * (NUM_DIMENSIONS - 1)) for x in all_x])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed67dec-caec-45fb-aee9-950482fc612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute peaks of CDFT\n",
    "# half_y_dft = np.abs(y_dft[NUM_POINTS // 2 + 1:])\n",
    "# rel_height = 1/3\n",
    "# max_height = np.max(half_y_dft)\n",
    "# peak_indices, _ = find_peaks(half_y_dft, height=rel_height * max_height)\n",
    "# if len(peak_indices) > 0:\n",
    "#     max_peak_idx = np.max(peak_indices)\n",
    "#     peak_width = peak_widths(x=half_y_dft, peaks=[max_peak_idx], rel_height=0.9)[0]\n",
    "#     cutoff_frequency = np.max(x_dft[round(max_peak_idx + peak_width[0])])\n",
    "# else:\n",
    "#     cutoff_frequency = 0.1\n",
    "# print(f\"Cutoff frequency: {cutoff_frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ab50c5-a842-4fbf-b05a-c521cdfc6306",
   "metadata": {},
   "source": [
    "# Random fourier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db72e7-8e4b-4d41-9b4d-c925b1eaff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1e-8\n",
    "ndim = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee8ca7-52bb-4c48-8516-995f4bbb2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    \"\"\"Square loss.\"\"\"\n",
    "    loss = jnp.sum((labels-predictions)**2)\n",
    "    loss = loss/len(labels)\n",
    "    return loss\n",
    "\n",
    "def cost(clf, input_data, labels):\n",
    "    \"\"\"Cost function.\"\"\"\n",
    "    predictions = clf.predict(input_data)\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe829948-6135-4ed5-a22d-e4198cf2874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "MAX_NUM_FREQUENCIES = 10\n",
    "while score < 0.1:\n",
    "    rbf_feature = RBFSampler(gamma=gamma, n_components=ndim)\n",
    "    X_features = rbf_feature.fit_transform(X)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y, test_size=0.2)\n",
    "    non_zero_coeffs = []\n",
    "    alpha = 1\n",
    "    while len(non_zero_coeffs) < MAX_NUM_FREQUENCIES and alpha > 1e-3:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"alpha = {alpha}\")\n",
    "        print(f\"gamma: {gamma}\")\n",
    "        print(f\"score: {score}\")\n",
    "        alpha /= 1.5\n",
    "        clf = Lasso(alpha=alpha)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        betas = clf.coef_\n",
    "        non_zero_coeffs = betas[betas != 0]\n",
    "    score = clf.score(X_test, Y_test)\n",
    "    gamma *= 2\n",
    "\n",
    "clear_output(wait=True)\n",
    "lasso_loss = cost(clf, X_test, Y_test)\n",
    "print(f\"Loss: {lasso_loss}\")\n",
    "print(f\"Fitting score: {score}\")\n",
    "print(f\"Number of non-zero coefficients: {len(non_zero_coeffs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be109a8c-b342-47e0-b950-93aa028868ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights of feature space\n",
    "weights = rbf_feature.random_weights_\n",
    "# Filter coefficients\n",
    "REL_THRESHOLD = 0.2\n",
    "indices = np.abs(betas) >= np.max(np.abs(betas)) * REL_THRESHOLD\n",
    "betas = betas[indices]\n",
    "weights = weights[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a75f1-a70c-4bea-a6e4-f00c6309214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_frequencies = np.sort(np.max(np.abs(weights), axis=1))\n",
    "print(f\"Cutoff freqs: {cutoff_frequencies}\")\n",
    "if CUSTOM_DATASET:\n",
    "    print(f\"Maximum freqs: {np.max(freqs, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c364c9ee-3e20-41dc-b181-750c2ee755a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 1\n",
    "plt.plot(Y[:200])\n",
    "plt.plot(clf.predict(X_features[:200]), color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e776db-3ad9-4207-8bc7-d75933771928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.xticks(np.linspace(np.min(weights[0]), np.max(weights[0]), 8))\n",
    "# plt.bar(weights[0], np.abs(betas), width=(np.max(weights[0]) - np.min(weights[0])) / len(weights[0]) / 3)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c0c72-6f51-4952-956f-464a3cf74179",
   "metadata": {},
   "source": [
    "# Quantum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b79528-a479-432e-88eb-6561e3cfebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226d910-042b-4c50-a342-2c913a6cf5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circuit\n",
    "dev = qml.device(\"default.qubit\", wires=NUM_DIMENSIONS)\n",
    "@jax.jit\n",
    "@qml.qnode(dev,interface=\"jax\")\n",
    "def circuit(weights, scaling, input_data):\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        StronglyEntanglingLayers(weights=weights[:-1], wires=list(range(NUM_DIMENSIONS)))\n",
    "        for dim in range(NUM_DIMENSIONS):\n",
    "            qml.RX(input_data[dim] * scaling[layer, dim], wires=dim)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "vcircuit = jax.vmap(circuit, (None, None, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7c400-7d96-4ed1-9976-f1ef28dbd1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    \"\"\"Square loss.\"\"\"\n",
    "    loss = jnp.sum((labels-predictions)**2)\n",
    "    loss = loss/len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790e80d-cbd4-4344-9cff-a3324d8bbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_data, labels):\n",
    "    \"\"\"Cost function.\"\"\"\n",
    "    predictions = variational_classifier(params['w'], params['s'], params['a'], input_data)\n",
    "    return square_loss(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5c480-2e5e-49d3-ab53-5f447eee2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, scaling, final_scaling, input_data):\n",
    "    \"\"\"Add classical bias.\"\"\"\n",
    "    return final_scaling * vcircuit(weights, scaling, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb7b33-9f06-4480-8440-8d6b66dad11f",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577fbe8-749b-431b-8107-f6fbb381220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_DIMENSIONS > 1:\n",
    "    gammas = [cutoff_frequencies[i] / NUM_LAYERS for i in range(NUM_DIMENSIONS)]\n",
    "else:\n",
    "    gammas = cutoff_frequencies[0] / NUM_LAYERS\n",
    "print(f\"Gammas: {gammas}\")\n",
    "params = {'w': pnp.random.random((NUM_LAYERS, NUM_DIMENSIONS, 3), requires_grad=True),\n",
    "          'a': pnp.ones(1, requires_grad=True) * np.max(Y),\n",
    "          's':pnp.ones((NUM_LAYERS, NUM_DIMENSIONS), requires_grad=True) * gammas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243fc4c-0807-416b-a4f0-425e6dd2bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "LR = 3e-3\n",
    "optimizer = optax.adam(LR)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6cb0dd-47b5-41a5-9771-bc2fd7ea7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "if CUSTOM_DATASET:\n",
    "    x_points = []\n",
    "    y_points = []\n",
    "    for i in range(NUM_DIMENSIONS):\n",
    "        points = np.zeros((NUM_POINTS, NUM_DIMENSIONS))\n",
    "        points[:, i] += np.linspace(0, 100 / MAX_FREQUENCY, NUM_POINTS)\n",
    "        x_points.append(points)\n",
    "        y_points.append(np.array([f(point) for point in points]))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "train_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d3fbf-c87b-4607-a543-a5b7ffec9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(5000):\n",
    "    train_cost, grads = jax.value_and_grad(cost)(params, X_train, Y_train)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    # s_temp = params['s']\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    # params['s']=s_temp\n",
    "    \n",
    "    model_plot = variational_classifier(params['w'], params['s'], params['a'], X)\n",
    "    test_cost = cost(params, X_test, Y_test)\n",
    "    test_loss.append(test_cost)\n",
    "    train_loss.append(train_cost)\n",
    "    \n",
    "    if it%10==0:\n",
    "        clear_output(wait=True)\n",
    "        fig, [ax0, ax1] = plt.subplots(2, 1, figsize=(11, 8))\n",
    "        ax0.set_title(f\"Iter: {it + 1:5d} | Cost: {test_cost:0.7f}\", fontsize='large', loc='left', fontweight='bold', style='italic', family='monospace')\n",
    "        ax0.set_title(f\"# samples: {X.shape[0]}, # features: {X.shape[1]}\", fontsize='large', loc='right', fontweight='bold', style='italic', family='monospace')\n",
    "        plt.suptitle(f\"\"\"Training of a QML model with {NUM_DIMENSIONS} wires and {NUM_LAYERS} layers.\"\"\")\n",
    "        ax0.set_ylabel(\"f(x)\")\n",
    "        ax0.set_xlabel(\"Input idx\")\n",
    "        ax0.plot(model_plot, label='model')\n",
    "        ax0.plot(Y, linestyle='dashed',label='ground_truth')\n",
    "        ax0.legend()\n",
    "        ax1.set_ylabel(\"f(x)\")\n",
    "        ax1.set_xlabel(\"Input idx\")\n",
    "        ax1.plot(model_plot[:200], label='model')\n",
    "        ax1.plot(Y[:200], linestyle='dashed',label='ground_truth')\n",
    "        ax1.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"images/training_{it}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab399fc-3348-408a-8f30-a3d51d3f3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(len(train_loss)))\n",
    "y = [lasso_loss for _ in x]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Train/test loss\")\n",
    "plt.plot(train_loss, color=\"red\", label=\"Train\")\n",
    "plt.plot(test_loss, color=\"blue\", label=\"Test\")\n",
    "plt.plot(x, y, label=\"Lasso regression\")\n",
    "plt.yscale('log')\n",
    "plt.ylabel(\"Mean squared error\")\n",
    "plt.xlabel(\"Num. iterations\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d31e0-2bda-439d-86f8-11b26062f7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackweek",
   "language": "python",
   "name": "hackweek"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
